{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Rivulet: U. S. EPA Air Quality System\n",
    "_by Michelle H Wilkerson, Lucas Coletti, and Adelmo Eloy_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Purpose of this Notebook\n",
    "\n",
    "This notebook is focused on **Air Quality** as a phenomenon. While most students understand that poor Air Quality can impact health, they may not know that there are many different kinds of air pollution, each caused by different processes and chemicals. These are reflected by different patterns over the course of a day, week, major event, or year.\n",
    "\n",
    "<details>\n",
    "    <summary>Click here for more information</summary>\n",
    "This data tool allows users to connect to the U. S. Environmental Protection Agency's Air Quality System (AQS) API, which provides air quality data for dates up to six months before the present date (the time lag allows for data to be scientifically validated). You are able to search for air quality data streams in an area of interest, identify a date range of interest within that area, and then access a variety of combinations of data that allow for explorations of different pollutants, comparison of AQI across different regions, and more. The datasets this notebook is constucted to fetch can serve as a launching point for examining what air quality is, and what are its underlying mechanistic and compositional complexities.\n",
    "\n",
    "You are welcome to modify and adapt this script. You may find the AQS API documentation [here](https://aqs.epa.gov/aqsweb/documents/data_api.html) and the `pyaqsapi` documentation [here](https://usepa.github.io/pyaqsapi/) helpful.\n",
    "\n",
    "This notebook was developed as part of NSF Grant 2445609 to support accessing and processing public datasets for middle and high school classroom activities. It's written to be relatively accessible to beginners, but if you have not interacted with computational notebooks or Python before, you may find navigating this tool difficult. (Check out the Show Your Work project for a gentle introduction to computational notebooks for educators!)\n",
    "\n",
    "Our project is focused on supporting data analysis and mechanistic reasoning in science education. In other words, we want students to learn how data provides information about _how scientific mechanisms work_ and how understanding scientific mechanisms can help them to _explain and interpret patterns in data_. This builds on a long history of research on complex systems and agent-based modeling, and more closely connects that work to current expansions of data analysis across subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Part I: Connecting with AQS\n",
    "\n",
    "Before you get started, you will need an AQS API Key. To get one, use the url `https://aqs.epa.gov/data/api/signup?email=myemail@example.com` (replace myemail@example.com with your email) and paste it into a browser. You will receive a cute sounding API key via email to the address you provided in the URL. \n",
    "\n",
    "Copy your API key and change EMAIL and API_KEY in the cell block below to your email and key from the service. \n",
    "\n",
    "You can run the notebook using the test email and key that are already provided, however, the test account has a limited number of uses per day and may not work. Register for an account as soon as you know you'd like to use the service. If you lose your key and need a new one, use the same url with the same email address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT BELOW: Depending on what tool you are using to run this \n",
    "# notebook, you may need to replace the \"%\"\" below with \"!\"\n",
    "%pip install pyaqsapi # This installs the AQS API package from the EPA\n",
    "\n",
    "EMAIL = \"test@aqs.api\" # EDIT HERE: with your registered email\n",
    "API_KEY = \"test\" # EDIT HERE: with your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "The `pyaqsapi` package provides our requested data as pandas dataframes. Below, we run a query to see if the service is available. We've found this service in particular to be finicky at times. If you don't get a successful response on a query, take a break and try again later. Remember that you are more likely to get a successful response if you use your own API key rather than the test key provided here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaqsapi as aqs\n",
    "\n",
    "aqs.aqs_credentials(username=EMAIL, key=API_KEY)\n",
    "\n",
    "aqs.aqs_is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Part II: Identifying a Focal Location and Date\n",
    "\n",
    "This section allows you to specify a location and a date for which you would like to collect data. You'll need to know the approximate longitude and latitude of the region you are interested in. One easy way to do this is by asking Google, \"What is the longitude and latitude of [area]?\" You will use the code in this section to use a minimum and maximum latitude and longitude to draw a bounding box around your location of interest. This will filter your future queries to focus only on air quality sensors found within that box. If you don't find any sensors, select a different location or increase the bounding box size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Now, let's identify a location and time period that we want to explore. AQS can fetch data within a bounding box. Let's not get crazy - start with a relatively small bounding box (try one degree for an urban area) and get bigger if you need to. (Tip: If you click on a location in Google Maps, you'll see the lat and long for that point in the URL.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a bounding box around your target region. \n",
    "# If it is densely populated, we suggest you start with \n",
    "# a bounding box that is only one degree in area. \n",
    "\n",
    "min_lat = 37 # EDIT HERE\n",
    "max_lat = 38 # EDIT HERE\n",
    "\n",
    "min_long = -122.5 # EDIT HERE\n",
    "max_long = -121.5 # EDIT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is unnecessary but sort of luxurious. let's map the box to\n",
    "# make sure we're capturing what we want.\n",
    "\n",
    "%pip install folium\n",
    "import folium\n",
    "\n",
    "bbox = [[min_lat, min_long], [max_lat, max_long]]\n",
    "\n",
    "# Calculate the center of the box to position the map\n",
    "map_center = [(bbox[0][0] + bbox[1][0]) / 2, (bbox[0][1] + bbox[1][1]) / 2]\n",
    "\n",
    "# Create a Folium map object\n",
    "m = folium.Map(location=map_center, zoom_start=8)\n",
    "\n",
    "# Add a rectangle for the bounding box to the map\n",
    "folium.Rectangle(\n",
    "    bounds=bbox,\n",
    "    color=\"#ff0000\",        # Red border\n",
    "    fill=True,\n",
    "    fill_color=\"#ff7800\",   # Orange fill\n",
    "    fill_opacity=0.2\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify a target date to be included in your retrieval.\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "target_date = \"04-10-2020\" # EDIT HERE\n",
    "target_datetime = datetime.strptime(target_date, \"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "AQS has settings for different collections of parameters that reflect different \"classes\" of interest. For example, one parameter is SCHOOL AIR TOXICS, which highlights 125 pollutants, or HAZARDOUS AIR POLLUTANTS with a total of 407 pollutants (!). Since we're only interested in O3 and PM, let's find a class that has those two and not much else so we're not taxing the system with our queries. AQI POLLUTANTS looks like a good one, it tracks the \"big five\" pollutants that are most commonly discussed along with a few other well known pollutants: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "From this list, you can select the specific AQI pollutant parameters that you want to fetch from any of the sequences below. We suggest Ozone (O3) and PM2.5, or Carbon monoxide (CO) and PM2.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Part III: Fetching PM2.5 and O3 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    parameter_list = aqs.aqs_parameters_by_class(\"AQI POLLUTANTS\")\n",
    "except Exception as e:\n",
    "    print(f\"Something didn't work: {e}\")\n",
    "\n",
    "parameter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the parameters that you want to include in your dataset.\n",
    "# By default, the list below includes Ozone and PM2.5, which have very\n",
    "# different dynamics. \n",
    "\n",
    "PARAMETERS = ('44201', '88101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code figures out what monitoring stations have the information you need.\n",
    "\n",
    "bdate = target_datetime\n",
    "edate = target_datetime + timedelta(days=1)\n",
    "\n",
    "monitors = aqs.bybox.monitors(\n",
    "    parameter= ','.join(PARAMETERS), # all six pollutants are listed\n",
    "    bdate=bdate, \n",
    "    edate=edate,\n",
    "    minlat=min_lat,\n",
    "    maxlat=max_lat,\n",
    "    minlon=min_long,\n",
    "    maxlon=max_long,\n",
    ")\n",
    "\n",
    "# Filter the monitors so we are showing only the ones that have all requested parameters\n",
    "relevant_monitors = monitors.groupby(\n",
    "    ['state_code','county_code','site_number']).filter( # make groups of each monitor\n",
    "    lambda group: set(group['parameter_code']) == set(PARAMETERS) # include only groups with both monitors\n",
    ")\n",
    "\n",
    "\n",
    "relevant_monitors[['state_code','county_code','site_number','address','city_name','county_name','state_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Hopefully, at least one monitor in your designated area appeared that has all pollutants. If not, you may want to remove less commonly measured pollutants from the lambda filter above and see how close you can get.\n",
    "\n",
    "In the code below we specify how many weeks of data we'd like to fetch around our target date. \n",
    "\n",
    "Now, let's identify the monitoring station we want from the table above, and enter the corresponding stateFIPS, countycode, and sitenum to get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOMIZE THIS: Define the period of time for which you would like to fetch \n",
    "# data. By default, the code below specifies a beginning date of one week\n",
    "# before the target date, and and end date of one week after.\n",
    "\n",
    "beginningdate = target_datetime - timedelta(weeks=1)\n",
    "enddate = target_datetime + timedelta(weeks=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOMIZE THIS: Enter the stateFIPS, county_code, and sitenum of your preferred \n",
    "# monitoring station from the list above. By default, we have set this to a\n",
    "# monitoring station in Concord, CA that we know reports all AQI pollutants.\n",
    "\n",
    "aqdata = aqs.bysite.sampledata(parameter=','.join(PARAMETERS),\n",
    "                      bdate=beginningdate,\n",
    "                      edate=enddate,\n",
    "                      stateFIPS=\"06\", # enter the state_code here\n",
    "                      countycode=\"001\", # enter the county_code here\n",
    "                      sitenum=\"0013\") # enter the site_number here\n",
    "\n",
    "aqdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Our data has dates and times, but not a combined datetime field. Let's make one for easier plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqdata['datetime_local'] = aqdata.apply(lambda row: datetime.strptime(f\"{row['date_local']} {row['time_local']}\", \"%Y-%m-%d %H:%M\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS: Plot a grid of reported levels for each pollutant, plus composite AQI\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "g = sns.FacetGrid(aqdata, \n",
    "                  row=\"parameter_code\", \n",
    "                  aspect=4, # this makes the graphs 4x wider than they are tall\n",
    "                  sharey=False) # this treats the scale for each pollutant separately\n",
    "\n",
    "g.map(sns.lineplot, \"datetime_local\", \"sample_measurement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the aqdata so each row is a datetime and columns are parameter codes\n",
    "# We can add more data from the original table as needed\n",
    "aqdata_pivoted = aqdata.pivot_table(\n",
    "    index='datetime_local',\n",
    "    columns='parameter_code',\n",
    "    values='sample_measurement'\n",
    ").reset_index()\n",
    "\n",
    "aqdata_pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "If this set of data looks interesting enough to keep working with, use the code below to export to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqdata_pivoted.to_csv(\"pollutantlevels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Part IV: Reconstructing AQI from Pollutant Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "AQI is what's know as a composite index. It looks at the concentrations and risk levels of a core set of six major pollutants (the ones we reviewed as AQI POLLUTANTS above), and reports the highest risk level from those pollutants at a given time. \n",
    "\n",
    "The AQI is one number, and every 50 points represents a new level of hazard. The graphic below shows the general breakdown of AQI warning levels. \n",
    "\n",
    "<img src=\"https://cap-mzansi.com/wp-content/uploads/2023/06/shutterstock_1657303105-1536x602.webp\" alt=\"alt text\" width=\"500\">\n",
    "\n",
    "In the block below, we define what the EPA calles AQI \"breakpoints\" - these define how different pollutant measures are translated into risk levels that can be compared.\n",
    "\n",
    "The code below should not be edited unless you know what you're doing, so we've left it collapsed. Think of it as extra background work to get you the data you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "The functions we defined above report the AQI, given each constituent pollutant's concentration. Now what we want to do is find the monitoring stations that report all the necessary pollutants. Below, we include all six of the pollutants in the list called PARAMETERS. If you cannot find any monitoring stations that are tracking all the parameters, try reducing the full list to subsets of pollutants that are most frequently monitored, or that are most important for the region you are exploring (if you are not sure, we suggest trying PM10, PM2.5, and Ozone). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOMIZE THIS: Identify the parameters that you want to include in your dataset.\n",
    "# By default, the list below includes Ozone and PM2.5, which tend to have very\n",
    "# different dynamics. \n",
    "\n",
    "# TODO modularize so that the user can just go to the last section and \n",
    "# perhaps reset the parameters? Chat with a few users.\n",
    "\n",
    "PARAMETERS = ('44201', '88101', '42101', '42401', '42602', '81102')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS: This code figures out what monitoring stations have the information you need.\n",
    "\n",
    "bdate = target_datetime\n",
    "edate = target_datetime + timedelta(days=1)\n",
    "\n",
    "monitors = aqs.bybox.monitors(\n",
    "    parameter= ','.join(PARAMETERS), # all six pollutants are listed\n",
    "    bdate=bdate, \n",
    "    edate=edate,\n",
    "    minlat=min_lat,\n",
    "    maxlat=max_lat,\n",
    "    minlon=min_long,\n",
    "    maxlon=max_long,\n",
    ")\n",
    "\n",
    "# Filter the monitors so we are showing only the ones that have all requested parameters\n",
    "relevant_monitors = monitors.groupby(\n",
    "    ['state_code','county_code','site_number']).filter( # make groups of each monitor\n",
    "    lambda group: set(group['parameter_code']) == set(PARAMETERS) # include only groups with both monitors\n",
    ")\n",
    "\n",
    "\n",
    "relevant_monitors[['state_code','county_code','site_number','address','city_name','county_name','state_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOMIZE THIS: Define the period of time for which you would like to fetch \n",
    "# data. By default, the code below specifies a beginning date three days before\n",
    "# the target date, and three days after (about a week of data).\n",
    "\n",
    "beginningdate = target_datetime - timedelta(weeks=1)\n",
    "enddate = target_datetime + timedelta(weeks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOMIZE THIS: Enter the stateFIPS, county_code, and sitenum of your preferred \n",
    "# monitoring station from the list above. By default, we have set this to a\n",
    "# monitoring station in Concord, CA that we know reports all AQI pollutants.\n",
    "\n",
    "aqdata = aqs.bysite.sampledata(parameter=','.join(PARAMETERS),\n",
    "                      bdate=beginningdate,\n",
    "                      edate=enddate,\n",
    "                      stateFIPS=\"06\", # enter the state_code here\n",
    "                      countycode=\"013\", # enter the county_code here\n",
    "                      sitenum=\"0002\") # enter the site_number here\n",
    "\n",
    "aqdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS: Define the EPA Air Quality Index (AQI) Breakpoints\n",
    "# Format: (AQI_Low, AQI_High, Conc_Low, Conc_High)\n",
    "AQI_BREAKPOINTS = {\n",
    "    # PM2.5 (24-hr, in µg/m³)\n",
    "    '88101': [\n",
    "        (0, 50, 0.0, 12.0),\n",
    "        (51, 100, 12.1, 35.4),\n",
    "        (101, 150, 35.5, 55.4),\n",
    "        (151, 200, 55.5, 150.4),\n",
    "        (201, 300, 150.5, 250.4),\n",
    "        (301, 400, 250.5, 350.4),\n",
    "        (401, 500, 350.5, 500.4),\n",
    "    ],\n",
    "    # PM10 (24-hr, in µg/m³)\n",
    "    '81102': [\n",
    "        (0, 50, 0, 54),\n",
    "        (51, 100, 55, 154),\n",
    "        (101, 150, 155, 254),\n",
    "        (151, 200, 255, 354),\n",
    "        (201, 300, 355, 424),\n",
    "        (301, 400, 425, 504),\n",
    "        (401, 500, 505, 604),\n",
    "    ],\n",
    "    # O3 (8-hr, in ppm)\n",
    "    '44201': [\n",
    "        (0, 50, 0.000, 0.054),\n",
    "        (51, 100, 0.055, 0.070),\n",
    "        (101, 150, 0.071, 0.085),\n",
    "        (151, 200, 0.086, 0.105),\n",
    "        (201, 300, 0.106, 0.200),\n",
    "        # Note: AQI > 200 for 8-hr O3 is calculated using 1-hr O3.\n",
    "        # This implementation assumes you will provide the 8-hr value\n",
    "        # and will cap at the 201-300 range.\n",
    "    ],\n",
    "    # O3 (1-hr, in ppm) - Used when 8-hr values are high TODO\n",
    "    'O3_1hr': [\n",
    "        (101, 150, 0.125, 0.164),\n",
    "        (151, 200, 0.165, 0.204),\n",
    "        (201, 300, 0.205, 0.404),\n",
    "        (301, 400, 0.405, 0.504),\n",
    "        (401, 500, 0.505, 0.604),\n",
    "    ],\n",
    "    # CO (8-hr, in ppm)\n",
    "    '42101': [\n",
    "        (0, 50, 0.0, 4.4),\n",
    "        (51, 100, 4.5, 9.4),\n",
    "        (101, 150, 9.5, 12.4),\n",
    "        (151, 200, 12.5, 15.4),\n",
    "        (201, 300, 15.5, 30.4),\n",
    "        (301, 400, 30.5, 40.4),\n",
    "        (401, 500, 40.5, 50.4),\n",
    "    ],\n",
    "    # SO2 (1-hr, in ppb)\n",
    "    '42401': [\n",
    "        (0, 50, 0, 35),\n",
    "        (51, 100, 36, 75),\n",
    "        (101, 150, 76, 185),\n",
    "        (151, 200, 186, 304),\n",
    "        (201, 300, 305, 604),\n",
    "        (301, 400, 605, 804),\n",
    "        (401, 500, 805, 1004),\n",
    "    ],\n",
    "    # NO2 (1-hr, in ppb)\n",
    "    '42602': [\n",
    "        (0, 50, 0, 53),\n",
    "        (51, 100, 54, 100),\n",
    "        (101, 150, 101, 360),\n",
    "        (151, 200, 361, 649),\n",
    "        (201, 300, 650, 1249),\n",
    "        (301, 400, 1250, 1649),\n",
    "        (401, 500, 1650, 2049),\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS: Define functions to compute AQI composite measure.\n",
    "\n",
    "import math\n",
    "\n",
    "# different pollutant measurements are rounded to different places,\n",
    "# this function will do the specified rounding. (TODO: Check if we actually need\n",
    "# this depending on how data are reported by the AQS system)\n",
    "def truncate(n, decimals=0):\n",
    "    if not isinstance(n, (int, float)):\n",
    "        return None\n",
    "    if not math.isfinite(n):\n",
    "        return None\n",
    "    \n",
    "    multiplier = 10 ** decimals\n",
    "    return int(n * multiplier) / multiplier\n",
    "\n",
    "# Specification for truncation decimals\n",
    "POLLUTANT_SPECS = {\n",
    "    '88101': {'decimals': 1},\n",
    "    '81102': {'decimals': 0},\n",
    "    '44201': {'decimals': 3},\n",
    "    'O3_1hr': {'decimals': 3},\n",
    "    '42101': {'decimals': 1},\n",
    "    '42401': {'decimals': 0},\n",
    "    '42602': {'decimals': 0},\n",
    "}\n",
    "\n",
    "def calculate_individual_aqi(pollutant_code, concentration):\n",
    "    if pollutant_code not in AQI_BREAKPOINTS or \\\n",
    "       pollutant_code not in POLLUTANT_SPECS:\n",
    "        print(f\"Warning: Unknown pollutant code '{pollutant_code}'.\")\n",
    "        return None\n",
    "        \n",
    "    if concentration is None or concentration < 0 or \\\n",
    "       not math.isfinite(concentration):\n",
    "        return None\n",
    "\n",
    "    # 1. Truncate the concentration based on EPA spec\n",
    "    decimals = POLLUTANT_SPECS[pollutant_code]['decimals']\n",
    "    C_p = truncate(concentration, decimals)\n",
    "    \n",
    "    if C_p is None:\n",
    "        return None\n",
    "\n",
    "    # 2. Find the correct breakpoint category\n",
    "    table = AQI_BREAKPOINTS[pollutant_code]\n",
    "    \n",
    "    for (I_lo, I_hi, C_lo, C_hi) in table:\n",
    "        if C_lo <= C_p <= C_hi:\n",
    "            # 3. Apply the linear interpolation formula\n",
    "            # I_p = ((I_hi - I_lo) / (C_hi - C_lo)) * (C_p - C_lo) + I_lo\n",
    "            \n",
    "            # Avoid division by zero if C_hi == C_lo\n",
    "            if (C_hi - C_lo) == 0:\n",
    "                aqi = I_lo\n",
    "            else:\n",
    "                aqi = ((I_hi - I_lo) / (C_hi - C_lo)) * (C_p - C_lo) + I_lo\n",
    "                \n",
    "            return round(aqi)\n",
    "            \n",
    "    # If concentration is beyond the highest breakpoint,\n",
    "    # use the last category for calculation\n",
    "    (I_lo, I_hi, C_lo, C_hi) = table[-1]\n",
    "    if C_p > C_hi:\n",
    "        if (C_hi - C_lo) == 0:\n",
    "            aqi = I_lo\n",
    "        else:\n",
    "            aqi = ((I_hi - I_lo) / (C_hi - C_lo)) * (C_p - C_lo) + I_lo\n",
    "        return round(aqi)\n",
    "\n",
    "    return None # Should not be reached\n",
    "\n",
    "def calculate_composite_aqi(concentration_data):\n",
    "    individual_aqis = []\n",
    "    \n",
    "    for pollutant_code, concentration in concentration_data.items():\n",
    "        aqi = calculate_individual_aqi(pollutant_code, concentration)\n",
    "        \n",
    "        if aqi is not None:\n",
    "            individual_aqis.append(aqi)\n",
    "            \n",
    "    # The composite AQI is the highest of the available individual AQIs\n",
    "    if not individual_aqis:\n",
    "        return None\n",
    "        \n",
    "    return max(individual_aqis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS: Compute the individual AQI for each pollutant at each time point.\n",
    "\n",
    "aqdata['individual_aqi'] = aqdata.apply(\n",
    "    lambda row: calculate_individual_aqi(row['parameter_code'], row['sample_measurement']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS: Add the composite AQI for each time point to the table\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "combined_series = aqdata['date_local'] + ' ' + aqdata['time_local']\n",
    "aqdata['datetime_local'] = pd.to_datetime(combined_series, format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "# Pivot so each row is a datetime and columns are pollutant codes with their measurements\n",
    "measurements = aqdata.pivot_table(\n",
    "    index='datetime_local',\n",
    "    columns='parameter_code',\n",
    "    values='sample_measurement',\n",
    "    aggfunc='mean'  # if multiple readings per datetime/pollutant, take the mean\n",
    ")\n",
    "\n",
    "# Helper to build pollutant -> concentration dict and compute composite AQI\n",
    "def _row_to_composite(row):\n",
    "    conc = {str(code): row[code] for code in row.index if pd.notnull(row[code])}\n",
    "    return calculate_composite_aqi(conc)\n",
    "\n",
    "# Compute composite AQI for each datetime\n",
    "measurements['composite_aqi'] = measurements.apply(_row_to_composite, axis=1)\n",
    "\n",
    "# Make a tidy timeseries dataframe\n",
    "aqi_timeseries = measurements[['composite_aqi']].reset_index().sort_values('datetime_local')\n",
    "\n",
    "# Build new rows from the composite AQI timeseries and append to aqdata.\n",
    "# Reuse existing variables: aqi_timeseries, aqdata, pandas already imported.\n",
    "\n",
    "new_rows = pd.DataFrame({\n",
    "    'datetime_local': aqi_timeseries['datetime_local'],\n",
    "    'sample_measurement': aqi_timeseries['composite_aqi'],\n",
    "    'parameter_code': 'COMPOSITE_AQI',     # tag so these rows are identifiable\n",
    "    'parameter': 'Composite AQI',\n",
    "    'individual_aqi': aqi_timeseries['composite_aqi']\n",
    "})\n",
    "\n",
    "# Concatenate and keep a consistent datetime dtype; sort by datetime if desired.\n",
    "aqdata = pd.concat([aqdata, new_rows], ignore_index=True, sort=False)\n",
    "aqdata['datetime_local'] = pd.to_datetime(aqdata['datetime_local'])\n",
    "aqdata = aqdata.sort_values('datetime_local').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS: Plot a grid of reported levels for each pollutant, plus composite AQI\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# All that dataframe action messes us the indices. \n",
    "# We need to reset the index to visualize everything together.\n",
    "aqdata = aqdata.reset_index()\n",
    "\n",
    "g = sns.FacetGrid(aqdata, \n",
    "                  row=\"parameter_code\", \n",
    "                  aspect=4, # this makes the graphs 4x wider than they are tall\n",
    "                  sharey=False) # this treats the scale for each pollutant separately\n",
    "\n",
    "g.map(sns.lineplot, \"datetime_local\", \"sample_measurement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "If this is looking good, then you're ready to export to .csv to use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pivot so all mesures are collected in one row with the datetime \n",
    "aqdata = aqdata.pivot(index='datetime_local', columns='parameter_code', values='sample_measurement')\n",
    "\n",
    "aqdata.to_csv(\"aqipluspollutantlevels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Let's start by getting all the active Ozone and PM2.5 monitors in the bounding box during this target date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdate = target_datetime\n",
    "edate = target_datetime + timedelta(days=1)\n",
    "\n",
    "monitors = aqs.bybox.monitors(\n",
    "    parameter= \"44201,88101\", #44201 identifies ozone\n",
    "    bdate=bdate, \n",
    "    edate=edate,\n",
    "    minlat=min_lat,\n",
    "    maxlat=max_lat,\n",
    "    minlon=min_long,\n",
    "    maxlon=max_long,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter the monitors so we are showing only the ones that have all requested parameters\n",
    "relevant_monitors = monitors.groupby(\n",
    "    ['state_code','county_code','site_number']).filter( # make groups of each monitor\n",
    "    lambda group: set(group['parameter_code']) == {'44201','88101'} # include only groups with both monitors\n",
    ")\n",
    "\n",
    "\n",
    "relevant_monitors[['state_code','county_code','site_number','address','city_name','county_name','state_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Hopfully, the table above shows some candidate sites from which you can extract information about all of the pollutants you've identified. Let's choose one and take two weeks of sample data (that is the highest resolution of measurements available) around our target date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Part V: Finding Differences Among Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "In addition to identifying specific events that help you explore differential emission patterns among pollutants, you may want to explore smaller but more robust differences in emissions at near neighbor locations. This may be useful to think about the impacts of particular natural (e.g. a coastal breeze or mountains) or man-made features (e.g. the presence of a freeway or factory) on local air quality patterns over longer periods of time.\n",
    "\n",
    "This section helps you conduct a search within your defined bounding box  for the largest differences in mean concentrations between pollutants. \n",
    "\n",
    "NOTE: Right now I'm doing this for a one-month range around the specified datetime, but maybe talk to Helen or others about what kind of time range is reasonable. Let's identify the month first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the month around the target datetime specified above in Part II\n",
    "bdate = target_datetime - timedelta(days=2)\n",
    "edate = target_datetime + timedelta(days=2)\n",
    "\n",
    "# define the pollutant you want to explore across sites. Below, we model with PM2.5\n",
    "pollutants = \"88101\" ## TODO: Eventually, I think we can bring this out into the setup section since it's used everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Let's find the monitoring sites within the specified region that have the most dramatic differences in mean.\n",
    "\n",
    "The code below takes daily summaries for each site in the region, for the period of time specified above. It computes the means of these daily summaries for all sites, and then ranks the sites by mean. This isn't the only information we need, but it's a good first step for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS: For all sites within the bounding box\n",
    "# get the aggregated stats by site of the requested pollutant(s) \n",
    "\n",
    "aqsummary = aqs.bybox.dailysummary(parameter=\"88101\",\n",
    "                      bdate=bdate,\n",
    "                      edate=edate,\n",
    "                      minlat=min_lat,\n",
    "                      maxlat=max_lat,\n",
    "                      minlon=min_long,\n",
    "                      maxlon=max_long)\n",
    "\n",
    "# sort the sites from highest to lowest mean for\n",
    "# the parameter of interest.\n",
    "\n",
    "meanaq = aqsummary.groupby(\n",
    "    ['state_code', 'county_code', 'site_number']\n",
    ").mean(numeric_only=True).sort_values(\n",
    "    by=\"arithmetic_mean\", \n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "meanaq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Lets map these sites, in case the user has some insight and can validate whether this is something meaningful to look into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS: Map the sites above to review\n",
    "\n",
    "map_center = [meanaq['latitude'].mean(), meanaq['longitude'].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# 3. Loop through the DataFrame and add markers\n",
    "for index, row in meanaq.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        #popup=row['location_name'],  # Show the name on click\n",
    "        tooltip=row['arithmetic_mean'] # Show the name on hover\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "TODO: User identifies 2-3 sites. We pull data from those sites to construct the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "# Credit\n",
    "\n",
    "https://aqs.epa.gov/aqsweb/documents/about_aqs_data.html\n",
    "\n",
    "Gemini and VSCode Copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
